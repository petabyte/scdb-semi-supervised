{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel, BertConfig, BertForSequenceClassification\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "labeled_test_df = pd.read_pickle('test_data_unseen_bert_without_addl_data.zip', compression='zip')\n",
    "print(len(labeled_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_list = labeled_test_df['summary'].tolist()\n",
    "test_labels = np.array(labeled_test_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = 'scdb_train_tuned_model_without_addl_data'\n",
    "num_labels = 14\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'B', '##U', '##LL', '##OC', '##K', 'v', '.', 'South', 'Carolina', ',', 'No', '.', '78', ',', 'February', '20', ',', '1961', '.', 'Report', '##ed', 'below', ':', '235', 'S', '.', 'C', '.', '35', '##6', ',', '111', 'S', '.', 'E', '.', '2d', '65', '##7', '.', 'U', '.', 'S', '.', 'Supreme', 'Court', ':', '\"', 'The', 'w', '##rit', 'of', 'c', '##ert', '##ior', '##ari', 'is', 'dismissed', '.', 'The', 'total', '##ity', 'of', 'circumstances', 'as', 'the', 'record', 'makes', 'them', 'manifest', 'did', 'not', 'warrant', 'bringing', 'this', 'case', 'here', ',', 'and', 'the', 'w', '##rit', 'of', '##cer', '##ti', '##ora', '##ri', 'was', 'dismissed', '\"', 'The', 'case', 'was', 'decided', 'by', 'a', 'vote', 'of', '5', '-', '3', '.', 'The', 'decision', 'was', 'the', 'first', 'of', 'its', 'kind', 'in', 'the', 'Supreme', 'Court', 'of', 'the', 'United', 'States', '.', 'The', 'case', 'is', 'part', 'of', 'a', 'series', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Default MAX sequence length for BertModel\n",
    "MAX_SEQ_LENGTH = 128\n",
    "def pad_sequences(pad_token, seq_list, max_length):\n",
    "    return seq_list + [pad_token] * (max_length - len(seq_list))\n",
    "\n",
    "def pad_special_tokens(tokenized_text_sent):\n",
    "    if len(tokenized_text_sent) > MAX_SEQ_LENGTH - 2:\n",
    "           tokenized_text_sent = tokenized_text_sent[0:(MAX_SEQ_LENGTH - 2)]            \n",
    "    tokenized_text_sent.insert(0,'[CLS]')\n",
    "    tokenized_text_sent.append('[SEP]')\n",
    "    return tokenized_text_sent\n",
    "\n",
    "def tokenize_sentence(summary_text): \n",
    "    tokenized_text_sent = tokenizer.tokenize(summary_text[0]['summary_text'])                  \n",
    "    tokenized_text_sent = pad_special_tokens(tokenized_text_sent)\n",
    "    return tokenized_text_sent  \n",
    "\n",
    "tokenized_seq = list(map(tokenize_sentence, test_text_list))\n",
    "print(tokenized_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  101,   139,  2591, 23955,  9244,  2428,   191,   119,  1375,  2938,\n",
      "           117,  1302,   119,  5603,   117,  1428,  1406,   117,  2920,   119,\n",
      "          7178,  1174,  2071,   131, 19152,   156,   119,   140,   119,  2588,\n",
      "          1545,   117, 11084,   156,   119,   142,   119, 25712,  2625,  1559,\n",
      "           119,   158,   119,   156,   119,  3732,  2031,   131,   107,  1109,\n",
      "           192,  7729,  1104,   172,  7340, 18472,  7710,  1110,  6714,   119,\n",
      "          1109,  1703,  1785,  1104,  5607,  1112,  1103,  1647,  2228,  1172,\n",
      "         23487,  1225,  1136, 13178,  4362,  1142,  1692,  1303,   117,  1105,\n",
      "          1103,   192,  7729,  1104, 14840,  3121,  6533,  2047,  1108,  6714,\n",
      "           107,  1109,  1692,  1108,  1879,  1118,   170,  2992,  1104,   126,\n",
      "           118,   124,   119,  1109,  2383,  1108,  1103,  1148,  1104,  1157,\n",
      "          1912,  1107,  1103,  3732,  2031,  1104,  1103,  1244,  1311,   119,\n",
      "          1109,  1692,  1110,  1226,  1104,   170,  1326,   102]],\n",
      "       device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "def convert_tokens_to_tensor(tokenized_sentence_a):        \n",
    "    tokenized_text = []\n",
    "    tokenized_text.extend(tokenized_sentence_a)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    indexed_tokens = pad_sequences(0, indexed_tokens, MAX_SEQ_LENGTH)    \n",
    "    tokens_tensor = torch.tensor([indexed_tokens], device=device)\n",
    "    #generate the token type ids\n",
    "    token_type_ids = []\n",
    "    token_type_a = [0] * len(tokenized_sentence_a)\n",
    "    token_type_ids.extend(token_type_a)\n",
    "    token_type_ids = pad_sequences(0, token_type_ids, MAX_SEQ_LENGTH)    \n",
    "    token_type_tensor = torch.tensor([token_type_ids],device=device)\n",
    "    #generate the type ids\n",
    "    input_mask = [1] * len(tokenized_text)\n",
    "    input_mask = pad_sequences(0, input_mask, MAX_SEQ_LENGTH)    \n",
    "    input_tensor = torch.tensor([input_mask],device=device)\n",
    "    return [tokens_tensor, token_type_tensor, input_tensor]    \n",
    "\n",
    "converted_tensors = list(map(convert_tokens_to_tensor, tokenized_seq))\n",
    "print(converted_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "predictions = []\n",
    "for predict_record in converted_tensors:\n",
    "    outputs = model(predict_record[0], token_type_ids=predict_record[1], attention_mask=predict_record[2])\n",
    "    prediction = np.argmax(outputs[0][0].cpu().detach().numpy())\n",
    "    predictions.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.87      0.85       161\n",
      "         2.0       0.57      0.67      0.62        30\n",
      "         3.0       0.65      0.55      0.60        31\n",
      "         4.0       0.45      0.31      0.37        16\n",
      "         5.0       0.50      0.50      0.50         2\n",
      "         6.0       0.00      0.00      0.00         3\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         8.0       0.67      0.67      0.67        24\n",
      "         9.0       0.41      0.38      0.39        32\n",
      "        10.0       0.50      0.20      0.29         5\n",
      "        11.0       0.33      0.50      0.40         2\n",
      "        12.0       0.60      0.86      0.71         7\n",
      "        13.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.70       315\n",
      "   macro avg       0.42      0.42      0.41       315\n",
      "weighted avg       0.68      0.70      0.69       315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(test_labels, predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84592145 0.61538462 0.59649123 0.37037037 0.5        0.\n",
      " 0.         0.66666667 0.39344262 0.28571429 0.4        0.70588235\n",
      " 0.         0.41383643 0.68518082]\n",
      "[161  30  31  16   2   3   1  24  32   5   2   7   1 315 315]\n",
      "0.5947326889265513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py:498: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"_draw_bs_pairs\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mInvalid use of type(CPUDispatcher(<function _make_two_arg_numba_func.<locals>.f at 0x0000023681FBD708>)) with parameters (array(float64, 1d, C), array(float64, 1d, C), Tuple())\n",
      " * parameterized\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: type(CPUDispatcher(<function _make_two_arg_numba_func.<locals>.f at 0x0000023681FBD708>))\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py (510)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 510:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "            bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
      "\u001b[1m            bs_replicates[i] = f(bs_x, bs_y, args)\n",
      "\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @numba.jit\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py:498: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"_draw_bs_pairs\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 507:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "        # Generate replicates\n",
      "\u001b[1m        for i in range(size):\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @numba.jit\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\numba\\core\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"_draw_bs_pairs\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 501:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "        # Set up array of indices to sample from\n",
      "\u001b[1m        inds = np.arange(n)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\numba\\core\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 501:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "        # Set up array of indices to sample from\n",
      "\u001b[1m        inds = np.arange(n)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py:498: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"_draw_bs_pairs\" failed type inference due to: \u001b[1m\u001b[1m\u001b[1mInvalid use of type(CPUDispatcher(<function _make_two_arg_numba_func.<locals>.f at 0x0000023681FBD708>)) with parameters (array(float64, 1d, C), array(float64, 1d, C), Tuple())\n",
      " * parameterized\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: type(CPUDispatcher(<function _make_two_arg_numba_func.<locals>.f at 0x0000023681FBD708>))\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py (510)\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 510:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "            bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
      "\u001b[1m            bs_replicates[i] = f(bs_x, bs_y, args)\n",
      "\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @numba.jit\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\numba\\core\\object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"_draw_bs_pairs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 507:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "        # Generate replicates\n",
      "\u001b[1m        for i in range(size):\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "c:\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\numba\\core\\object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\users\\u0155811\\.conda\\envs\\tf-gpu\\lib\\site-packages\\dc_stat_think\\dc_stat_think.py\", line 507:\u001b[0m\n",
      "\u001b[1m    def _draw_bs_pairs(x, y):\n",
      "        <source elided>\n",
      "        # Generate replicates\n",
      "\u001b[1m        for i in range(size):\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43106837 0.74476862]\n",
      "0.5968977238078704\n",
      "0.0008330890442518795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "from scipy import stats\n",
    "import dc_stat_think as dcst\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Add the label 13 which was missed in the splits\n",
    "f1_score_list = []\n",
    "support =[]\n",
    "cr_dict = classification_report(test_labels, predictions, output_dict=True)\n",
    "for cr_value_dict in cr_dict.values():\n",
    "    if isinstance(cr_value_dict, dict):\n",
    "        f1_score_list.append(cr_value_dict['f1-score'])\n",
    "        support.append(cr_value_dict['support'])\n",
    "f1_score_np = np.array(f1_score_list)\n",
    "support_np = np.array(support)\n",
    "#Bootstrap sampling to calculate the confidence interval for f1-score\n",
    "def weighted_average(x, y):\n",
    "    return np.sum(x * y)/np.sum(y)\n",
    "\n",
    "def boostrap_weighted_avg(data,size):\n",
    "    return dcst.draw_bs_pairs(data, support, weighted_average, size=size)\n",
    "   \n",
    "print(f1_score_np)    \n",
    "print(support_np)\n",
    "print(weighted_average(f1_score_np, support_np))\n",
    "bs_weighted_avg = boostrap_weighted_avg(f1_score_np, 10000)\n",
    "print(np.percentile(bs_weighted_avg, [2.5, 97.5]))\n",
    "print(np.mean(bs_weighted_avg))\n",
    "print(stats.sem(bs_weighted_avg, axis=None, ddof=0))\n",
    "plt.hist(bs_weighted_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
